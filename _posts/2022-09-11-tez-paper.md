---
layout: post
title: "《Apache Tez: 用于建模和构建数据处理应用程序的统一框架》 论文"
categories: 软件技术
tags: Tez 论文
toc: true
---

* TOC
{:toc}


[《Apache Tez: A Unifying Framework for Modeling and Building Data Processing Applications》 论文](https://web.eecs.umich.edu/~mosharaf/Readings/Tez.pdf)，[本地文件(PDF, 1.8 MB)](/assets/file/Apache%20Tez%20A%20Unifying%20Framework%20for%20Modeling%20and%20Building%20Data%20Processing%20Applications.pdf)。

作者：Bikas Saha, Hitesh Shah, Siddharth Seth,
Gopal Vijayaraghavanh, Arun Murthyh, Carlo Curino

Hortonworks, Microsoft


## 摘要

Hadoop 的广泛成功已经引导出了一个以 YARN 资源管理层为基础的，快速发展且多样的应用引擎生态系统。
开源实现的 MapReduce 框架正慢慢地被一系列专门用于特定垂直领域的引擎所取代。
这导致了越来越多的分散和重复的工作，每一个新的垂直引擎都需要从头重新实现基本功能（例如：容错性、安全性、处理掉队任务等）。

在本文中，我们介绍了Apache Tez，这是一个开源的框架，旨在建立数据流驱动的工作。
Tez 提供了一个脚手架和库组件，可用于迅速建立可扩展和高效的以数据流为中心的引擎。
我们设计的核心是促进组件的重复使用，而不妨碍在性能导向的数据平面上可定制性。
事实上，这是与上一代系统（如 Dryad，MapReduce）相比的关键区别，也是与新兴系统（如 Spark）的关键区别，后者提供并规定了一个固定的数据平面实现。
此外，Tez 还提供了原生支持来构建运行时优化，例如 Hive 的动态分区修剪。

Tez 已经部署在雅虎、微软 Azure、LinkedIn 和众多 Hortonworks 客户的网站上，而且越来越多的引擎正在与之集成。
这证实了我们的直觉，即大多数流行的垂直引擎可以利用一套核心的构建块。
我们用定量的实验证据来补充现实世界的采用情况，在流行的基准测试（TPC-DS，TPC-H）和生产工作负载中，基于 Tez 的 Hive、Pig、Spark 和 Cascading 的实现要优于其原始基于 YARN 的实现。

## 1. 引言

大规模数据分析曾经是大型网络公司专用的特殊技术，如今已成为大多数现代组织可用和不可缺少的。
这一更广泛的用户群促进了对这一领域的兴趣，并导致了一个蓬勃发展的大数据产业。
在本文中，我们使用 Hadoop 生态系统的视角来描述整个行业的趋势，因为这为介绍我们的 Apache Tez 系统提供了理想的背景。
我们将把与相关项目，如Dryad、Nephele、Hyracks 等，更广泛的比较推迟到第 8 节，
这些项目不可否认地成为了 Tez 设计的灵感来源，有时甚至是蓝图。

Hadoop，最初被设计为一个单一用途的系统（运行 MapReduce 作业以建立网络索引），现在已经演变成一个万能的数据分析系统。
这个工作的第一阶段是在 MapReduce 上提出了更高层次的抽象，其中的例子有 Hive、Pig 和 Cascading。
这加快了 Hadoop 的应用，但也导致了效率低下和性能不佳。
这些限制和对更多灵活性和效率的压力导致了 Hadoop 被重新调整为一个通用的、类似操作系统的资源管理层，即 YARN，以及一个允许任意执行引擎的应用框架层。
这使得不同的应用程序可以共享一个集群，并使 MapReduce 仅为 Hadoop 生态系统中的另一个应用。
重要的例子有摆脱了 MapReduce 模型（和 runtime）的 Spark，Impala 和 Flink。
这加快了创新，但也导致了一个效率较低的生态系统，相同的通用功能在不同的框架中被重复创造，例如，MapReduce 和 Spark 独立开发了实现延迟调度的机制。

在本文中，我们介绍了 Tez，这个项目接受了向 YARN 的架构转变，并进一步推动了它，提出了一个可重用的、灵活的和可扩展的脚手架。
该脚手架可以支持面向数据流的框架，同时避免复制功能。
Tez 的 API 允许框架使用最少的代码对数据流程图的逻辑和物理语义进行清晰的建模。
需要澄清的是，Tez 是一个建立基于数据流的 runtime/引擎的库，而不是一个引擎本身。
例如，Hadoop 的 Hive runtime 引擎已经在 0.13 版本中被重写以使用 Tez。

Tez 的主要贡献如下：
1. 允许用户将计算建模为一个 DAG（有向无环图），类似于 Dryad/Nephele/Hyracks。它的创新之处在于对经典的顶点和边缘概念做了更精细的分解，为数据平面提供了更大的控制和扩展性。
2. 提供 API 来动态发展（更细粒度的）DAG 定义。这使得复杂的运行时查询操作成为可能，例如根据在线信息修剪数据分区。
3. 为最先进的功能提供可扩展和高效的实现，例如，与 YARN 兼容的安全性、数据本地化的感知、资源再利用、容错和推测。
4. 为框架编写者和研究人员提供了快速创新的机会，并通过可插拔的实验支持来创造现实世界的影响，并提供一个开放源码的社区来了解该项目并做出贡献。

Tez与许多其他的“统一框架”提案不同之处在于 1）经过验证的灵活性和动态适应性，2）对操作问题的关注（生产准备就绪），以及 3）由社区驱动的将 Tez 嵌入到多个现有的特定领域的引擎中。

这一点从 Tez 对 MapReduce、Hive、Pig、Spark、Flink、Cascading 和 Scalding 的支持，以及它在雅虎、微软 Azure、LinkedIn 以及其他一些使用 Hortonworks 数据平台的组织的生产数据处理集群的采用中得以验证。
除了讨论 Tez 的广泛实际应用外，我们展示了其支持 Hive、Pig 和 Spark 在运行标准的基准测试的能力，如 TPC-H 和 TPC-DS，以及在雅虎公司的生产工作负载。

本文的其余部分组织如下：第 2 节提供了更多的历史背景，以及设计 Tez 的理由。
而第 3 节则介绍了 Tez 的架构。第 4 节讨论了 Tez 的实现，并强调了对效率和生产的实用性考虑。
第 5 节和第 6 节致力于证明它的实际意义，介绍了真实的应用，以及广泛的实验评估。
最后，我们在第 7 和第 8 节中讨论了未来和相关的工作，并在第 9 节中得出结论。


## 2. 背景和理由

为了理解设计 Tez 的动机和原理，我们必须先提供一些术语的背景，以及 Hadoop 中分布式计算的历史。
对这个历史和动机的观点不感兴趣的读者，请直接跳到第 3 节，在那里我们将深入探讨 Tez 架构的技术问题。

_术语_。到目前为止，我们一直使用图的术语，来吸引读者的直觉。现在我们更精确地介绍我们的术语：
* **DAG**：有向无环图，代表数据处理工作流程的结构。数据沿着边的方向流动。
* **顶点（Vertex）**：代表处理流程上的一个逻辑步骤。一个处理步骤通过应用应用程序提供的代码来转换数据，过滤或修改数据。
* **逻辑 DAG**：逻辑 DAG 是由一组顶点组成的，其中每个顶点代表计算的一个特定步骤。
* **任务（Task）**：代表顶点中的一个工作单元。在分布式处理中，由单个顶点代表的逻辑工作在物理上被执行为一组任务（tasks），这些任务可能在集群的多个机器上运行。每个任务都是顶点的实例化，它处理该顶点的输入数据的一个子集（或分区）。
* **物理 DAG**：物理 DAG 包括一组任务，它们由逻辑 DAG 的顶点扩展而成。
* **边（Edge）**：代表生产者和消费者之间的数据移动。逻辑 DAG 顶点之间的边表示它们之间的逻辑数据依赖关系。物理 DAG 中任务之间的边代表任务之间的数据传输。

这适用于不同的步骤可以被分割成更小的部分，从而可以被并行处理的问题。通常情况下，分区与分布式的分片数据相一致，并试图将处理过程与分片数据放在一起，从而减少计算的成本。

_Hadoop 1 和 Hadoop 2（YARN）_。Hadoop 从一个 MapReduce 是其上唯一的执行引擎的单体软件栈起步。所有的数据处理的行为需要将逻辑转换成一个 MapReduce job 或者一系列的 MapReduce jobs 上。
MapReduce 也负责集群资源的管理和分配。Hadoop 2 是当前一代的 Hadoop，它创造出一个名为 YARN 的通用型的资源管理层来承接分离出的这些职责。
这个从 Hadoop 核心平台上分离出来的应用允许除了 MapReduce 之外的多种类型的应用跑在 Hadoop 集群上。之前的很多领域相关应用都依赖于 MapReduce 来执行它们的逻辑，比如 Apache Hive 用作 SQL-like 数据处理，Apache Pig 用作 ETL 脚本，Cascading 用作 Java 写的数据处理应用。现在这些应用都可以更定制化的实现它们的逻辑并且原生地跑在 YARN 上。

![Evolution of Hadoop](/assets/img/post/tez-evolution-of-hadoop.png "Evolution of Hadoop")

虽然定制化能带来性能上的优势，但有很大的可能来创建一套通用的构件块，这些应用可以使用这些构件块以实现在 YARN 上的自定义代码。
我们试图通过 Tez 来抓住这个机会，这一点接下来会讨论。对流行的 Hadoop 生态系统应用（诸如 Apache Hive、Pig、Spark 等）的分析表明，有一些通用的功能是它们都需要的。
这些功能包括从 YARN 协商资源，以运行应用程序的任务，处理集群内的安全问题，从硬件故障中恢复，发布度量和统计数据等。
这其中有很多是高度专业化、很难的基础设施，每个人从头开始构建时都必须复制这些基础设施。
一个共同的实现使编写应用程序更容易，因为它消除了应用程序编写者的负担，让他们专注于其应用程序的独特逻辑。

此后，除非另有说明，当我们提到 Hadoop 时，我们指的是以 YARN 作为底层资源分配层的 Hadoop 2 计算栈；而提到 Hadoop 生态系统则意味着包括在 YARN 上运行的开源和商业项目，如 Apache Hive、Pig 等。

提供这些共同特征的努力需要创建一个框架来表达和优化这些工作负载的模型。
然后这个模型可以通过一个共享的底层库在 YARN 应用框架上应用和执行。
以下是对这样一个共享库的合理要求，我们之前已经通过与 MapReduce 的比较强调了这一点，一个充当共享底层的通用引擎。

_表达能力_。MapReduce 有一个简单的建模 API 来描述计算，
它通过要求所有的应用算法转化为 map 和 reduce 函数来描述计算的情况。
正如其他学者所观察到的，这太有约束性了，而面向 DAG 的模型可以更自然地捕获更广泛的组合。因此，我们将 Tez 的中心模型也定义为围绕 DAG 的执行。
此外，MapReduce 还为运行在 map/reduce 步骤中的逻辑提供了内置的语义，并强加了一个数据在 map 和 reduce 步骤之间的 _sorted_ 和 _partitioned_ 移动。
这些内置的语义，在一些核心用例中是合理的，在许多其他情况下可能是纯粹的开销，甚至在某些情况下是不需要的。
需要注意的是，这里需要一个 API 来描述任意 DAG 的结构，而不会添加一些不相关的语义到 DAG 结构中。

_数据平面的可定制性_。一旦分布式计算的结构被定义，就可以有在该结构中执行的实际逻辑的各种实现。这些不同之处可能是算法上的，例如，不同的数据分区方式，或与使用不同的硬件有关，例如，如果可以的话使用远程内存访问（RDMA）。
如果在 MapReduce 中，引擎的内置语义使得这样的定制化很难，因为它们侵入了引擎本身的实现。其次，在集群上执行 MapReduce 作业的单体结构使得插入独立的的实现很困难。
这就促使由数据转换和数据移动定义出的数据平面需要完全可定制。
还需要可以对任务执行的不同方面进行建模，以允许个别的执行的不同方面，例如读取输入、处理数据等等，可以很容易地进行定制。
我们采访了 Hadoop 社区的几位成员，证实了对现有引擎的改进(例如，改变 MapReduce 中的 shuffle 行为）是很有必要的。

虽然其他框架已经支持了 DAG 中的更一般概念，但是它们也有与 MapReduce 一样的局限性，内置的语义和数据平面的实现。而 Tez 能提供更低层次的抽象，这使得这样的语义和特殊实现能基于基础的共享脚手架来实现。

_后绑定的 runtime 优化_。应用从性能上考虑它们的数据处理逻辑时需要做出后绑定的决定。算法应该能基于被读取到的数据动态地变化，比如 join 的策略和扫描的机制。如果应用更好地理解它地数据和环境，就能更好地调整分区数和工作分工。Hadoop 集群的使用和负载特征上可以非常动态。用户和 jobs 持续地进出集群，它们的资源利用率却各不相同。这使得一个应用很难基于当前的集群状态去确定它的运行特征。我们把 Tez 设计成可以在 runtime 时更新核心抽象以使后绑定和在线决策更容易实现。

这就是我们对建立 Tez 的历史背景和合理性的概述。我们现在转向 Tez 的高层次架构，并且提供对关键构建块的一些看法。


## 3. 架构

Apache Tez 被设计和开发成专注于解决上面讨论过的这些问题，简而言之，1）底层模型的表达，2）数据平面的可定制性，3）促进 runtime 优化。与其建立一个通用计算引擎，我们意识到需要 Tez 去提供一个统一的框架来创建专门的引擎，以便为他们的特定需求定制数据处理。Tez 解决了通用但却困难的问题，编排和在 Hadoop 上执行分布式数据处理应用，使得应用可以专注于提供特定的语义和优化。应用层和 Tez 库层的关注点有着清晰的分界。Apache Tez 提供了集群资源的协调，容错性，资源弹性，安全性，内置的性能优化以及一个可随时使用的共享组件库。应用程序提供自定义应用逻辑，自定义数据平面和专门的优化。

这就带来了三个主要的好处：1）摊销开发成本（Hive 和 Pig 在 6 个月内用 Tez 库完全重写了它们的引擎），2）改进的性能（我们将在第 6 节展示用 Tez 有最高到 10 倍的性能改进），3）让未来多个引擎的管道更高效，因为它们共享了一个底层库。

Tez 由一组定义数据处理的核心 API 和一个在集群上启动的编排框架。应用程序应该实现这些 API 为编排框架提供执行环境。把 Tez 当作一个用于创建表示数据流结构的脚手架的库是很有用的，应用程序把自己的逻辑（比如算子）和数据传输代码（比如从远程机器的磁盘上读入数据）注入其中。这个设计即是战术性的也是战略性的。长期来看，这使得应用程序保持对 Tez 的未知，短期来看，这让现有的应用程序如 Hive 或 Pig 在不大幅改变它们的核心操作管道下能用上 Tez。我们开始描述 DAG API 和 Runtime API。这些是应用程序主要面对的接口，用来描述应用的 DAG 结构和执行时的代码。接着我们解释由 VertexManagers 和 DataSourceInitializers 组成的基于事件的控制平面去支持运行时对 DAG 的优化。最后，在第 4 节我们描述在 Hadoop 集群上执行所有代码的基于 YARN 的编排框架。特别地，我们专注于这个实现的性能和生产准备方面。


### 3.1 DAG API





### 3.2 Runtime API

### 3.3 基于事件的控制面板

### 3.4 顶点管理器：动态适应执行

### 3.5 数据源初始器

## 4. 实现和使用性考虑

### 4.1 YARN 中的实现

### 4.2 执行效率

### 4.3 生产环境准备情况

## 5. 各种框架和接受度

### 5.1 Apache MapReduce

### 5.2 Apache Hive

### 5.3 Apache Pig

### 5.4 Apache Spark

### 5.5 Apache Flink

### 5.6 商业上的接受

### 5.7 部署

## 6. 实验结果

### 6.1 Hive 0.14 性能测试

### 6.2 Yahoo Hive 规模测试

### 6.3 Yahoo Pig 生产测试

### 6.4 Pig K-均值迭代测试

### 6.5 YARN 上的 Spark 多租户测试


## 7. 开源和未来的工作

## 8. 相关工作

## 9. 结论
