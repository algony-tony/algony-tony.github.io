---
layout: post
title: "《Apache Tez: 用于建模和构建数据处理应用程序的统一框架》 论文"
categories: 软件技术
tags: Tez 论文
toc: true
---

* TOC
{:toc}


[《Apache Tez: A Unifying Framework for Modeling and Building Data Processing Applications》 论文](https://web.eecs.umich.edu/~mosharaf/Readings/Tez.pdf)，[本地文件(PDF, 1.8 MB)](/assets/file/Apache%20Tez%20A%20Unifying%20Framework%20for%20Modeling%20and%20Building%20Data%20Processing%20Applications.pdf)。

作者：Bikas Saha, Hitesh Shah, Siddharth Seth,
Gopal Vijayaraghavanh, Arun Murthyh, Carlo Curino

Hortonworks, Microsoft


## 摘要

Hadoop 的广泛成功已经引导出了一个以 YARN 资源管理层为基础的，快速发展且多样的应用引擎生态系统。
开源实现的 MapReduce 框架正慢慢地被一系列专门用于特定垂直领域的引擎所取代。
这导致了越来越多的分散和重复的工作，每一个新的垂直引擎都需要从头重新实现基本功能（例如：容错性、安全性、处理掉队任务等）。

在本文中，我们介绍了Apache Tez，这是一个开源的框架，旨在建立数据流驱动的工作。
Tez 提供了一个脚手架和库组件，可用于迅速建立可扩展和高效的以数据流为中心的引擎。
我们设计的核心是促进组件的重复使用，而不妨碍在性能导向的数据平面上可定制性。
事实上，这是与上一代系统（如 Dryad，MapReduce）相比的关键区别，也是与新兴系统（如 Spark）的关键区别，后者提供并规定了一个固定的数据平面实现。
此外，Tez 还提供了原生支持来构建运行时优化，例如 Hive 的动态分区修剪。

Tez 已经部署在雅虎、微软 Azure、LinkedIn 和众多 Hortonworks 客户的网站上，而且越来越多的引擎正在与之集成。
这证实了我们的直觉，即大多数流行的垂直引擎可以利用一套核心的构建块。
我们用定量的实验证据来补充现实世界的采用情况，在流行的基准测试（TPC-DS，TPC-H）和生产工作负载中，基于 Tez 的 Hive、Pig、Spark 和 Cascading 的实现要优于其原始基于 YARN 的实现。

## 1. 引言

大规模数据分析曾经是大型网络公司专用的特殊技术，如今已成为大多数现代组织可用和不可缺少的。
这一更广泛的用户群促进了对这一领域的兴趣，并导致了一个蓬勃发展的大数据产业。
在本文中，我们使用 Hadoop 生态系统的视角来描述整个行业的趋势，因为这为介绍我们的 Apache Tez 系统提供了理想的背景。
我们将把与相关项目，如Dryad、Nephele、Hyracks 等，更广泛的比较推迟到第 8 节，
这些项目不可否认地成为了 Tez 设计的灵感来源，有时甚至是蓝图。

Hadoop，最初被设计为一个单一用途的系统（运行 MapReduce 作业以建立网络索引），现在已经演变成一个万能的数据分析系统。
这个工作的第一阶段是在 MapReduce 上提出了更高层次的抽象，其中的例子有 Hive、Pig 和 Cascading。
这加快了 Hadoop 的应用，但也导致了效率低下和性能不佳。
这些限制和对更多灵活性和效率的压力导致了 Hadoop 被重新调整为一个通用的、类似操作系统的资源管理层，即 YARN，以及一个允许任意执行引擎的应用框架层。
这使得不同的应用程序可以共享一个集群，并使 MapReduce 仅为 Hadoop 生态系统中的另一个应用。
重要的例子有摆脱了 MapReduce 模型（和 runtime）的 Spark，Impala 和 Flink。
这加快了创新，但也导致了一个效率较低的生态系统，相同的通用功能在不同的框架中被重复创造，例如，MapReduce 和 Spark 独立开发了实现延迟调度的机制。

在本文中，我们介绍了 Tez，这个项目接受了向 YARN 的架构转变，并进一步推动了它，提出了一个可重用的、灵活的和可扩展的脚手架。
该脚手架可以支持面向数据流的框架，同时避免复制功能。
Tez 的 API 允许框架使用最少的代码对数据流程图的逻辑和物理语义进行清晰的建模。
需要澄清的是，Tez 是一个建立基于数据流的 runtime/引擎的库，而不是一个引擎本身。
例如，Hadoop 的 Hive runtime 引擎已经在 0.13 版本中被重写以使用 Tez。

Tez 的主要贡献如下：
1. 允许用户将计算建模为一个 DAG（有向无环图），类似于 Dryad/Nephele/Hyracks。它的创新之处在于对经典的顶点和边缘概念做了更精细的分解，为数据平面提供了更大的控制和扩展性。
2. 提供 API 来动态发展（更细粒度的）DAG 定义。这使得复杂的运行时查询操作成为可能，例如根据在线信息修剪数据分区。
3. 为最先进的功能提供可扩展和高效的实现，例如，与 YARN 兼容的安全性、数据本地化的感知、资源再利用、容错和推测。
4. 为框架编写者和研究人员提供了快速创新的机会，并通过可插拔的实验支持来创造现实世界的影响，并提供一个开放源码的社区来了解该项目并做出贡献。

Tez与许多其他的“统一框架”提案不同之处在于 1）经过验证的灵活性和动态适应性，2）对操作问题的关注（生产准备就绪），以及 3）由社区驱动的将 Tez 嵌入到多个现有的特定领域的引擎中。

这一点从 Tez 对 MapReduce、Hive、Pig、Spark、Flink、Cascading 和 Scalding 的支持，以及它在雅虎、微软 Azure、LinkedIn 以及其他一些使用 Hortonworks 数据平台的组织的生产数据处理集群的采用中得以验证。
除了讨论 Tez 的广泛实际应用外，我们展示了其支持 Hive、Pig 和 Spark 在运行标准的基准测试的能力，如 TPC-H 和 TPC-DS，以及在雅虎公司的生产工作负载。

本文的其余部分组织如下：第 2 节提供了更多的历史背景，以及设计 Tez 的理由。
而第 3 节则介绍了 Tez 的架构。第 4 节讨论了 Tez 的实现，并强调了对效率和生产的实用性考虑。
第 5 节和第 6 节致力于证明它的实际意义，介绍了真实的应用，以及广泛的实验评估。
最后，我们在第 7 和第 8 节中讨论了未来和相关的工作，并在第 9 节中得出结论。


## 2. 背景和理由

为了理解设计 Tez 的动机和原理，我们必须先提供一些术语的背景，以及 Hadoop 中分布式计算的历史。
对这个历史和动机的观点不感兴趣的读者，请直接跳到第 3 节，在那里我们将深入探讨 Tez 架构的技术问题。

_术语_。到目前为止，我们一直使用图的术语，来吸引读者的直觉。现在我们更精确地介绍我们的术语：
* **DAG**：有向无环图，代表数据处理工作流程的结构。数据沿着边的方向流动。
* **顶点（Vertex）**：代表处理流程上的一个逻辑步骤。一个处理步骤通过应用应用程序提供的代码来转换数据，过滤或修改数据。
* **逻辑 DAG**：逻辑 DAG 是由一组顶点组成的，其中每个顶点代表计算的一个特定步骤。
* **任务（Task）**：代表顶点中的一个工作单元。在分布式处理中，由单个顶点代表的逻辑工作在物理上被执行为一组任务（tasks），这些任务可能在集群的多个机器上运行。每个任务都是顶点的实例化，它处理该顶点的输入数据的一个子集（或分区）。
* **物理 DAG**：物理 DAG 包括一组任务，它们由逻辑 DAG 的顶点扩展而成。
* **边（Edge）**：代表生产者和消费者之间的数据移动。逻辑 DAG 顶点之间的边表示它们之间的逻辑数据依赖关系。物理 DAG 中任务之间的边代表任务之间的数据传输。

这适用于不同的步骤可以被分割成更小的部分，从而可以被并行处理的问题。通常情况下，分区与分布式的分片数据相一致，并试图将处理过程与分片数据放在一起，从而减少计算的成本。

_Hadoop 1 和 Hadoop 2（YARN）_。Hadoop 从一个 MapReduce 是其上唯一的执行引擎的单体软件栈起步。所有的数据处理的行为需要将逻辑转换成一个 MapReduce job 或者一系列的 MapReduce jobs 上。
MapReduce 也负责集群资源的管理和分配。Hadoop 2 是当前一代的 Hadoop，它创造出一个名为 YARN 的通用型的资源管理层来承接分离出的这些职责。
这个从 Hadoop 核心平台上分离出来的应用允许除了 MapReduce 之外的多种类型的应用跑在 Hadoop 集群上。之前的很多领域相关应用都依赖于 MapReduce 来执行它们的逻辑，比如 Apache Hive 用作 SQL-like 数据处理，Apache Pig 用作 ETL 脚本，Cascading 用作 Java 写的数据处理应用。现在这些应用都可以更定制化的实现它们的逻辑并且原生地跑在 YARN 上。

![Evolution of Hadoop](/assets/img/post/tez-evolution-of-hadoop.png "Evolution of Hadoop")

虽然定制化能带来性能上的优势，但有很大的可能来创建一套通用的构件块，这些应用可以使用这些构件块以实现在 YARN 上的自定义代码。
我们试图通过 Tez 来抓住这个机会，这一点接下来会讨论。对流行的 Hadoop 生态系统应用（诸如 Apache Hive、Pig、Spark 等）的分析表明，有一些通用的功能是它们都需要的。
这些功能包括从 YARN 协商资源，以运行应用程序的任务，处理集群内的安全问题，从硬件故障中恢复，发布度量和统计数据等。
这其中有很多是高度专业化、很难的基础设施，每个人从头开始构建时都必须复制这些基础设施。
一个共同的实现使编写应用程序更容易，因为它消除了应用程序编写者的负担，让他们专注于其应用程序的独特逻辑。

此后，除非另有说明，当我们提到 Hadoop 时，我们指的是以 YARN 作为底层资源分配层的 Hadoop 2 计算栈；而提到 Hadoop 生态系统则意味着包括在 YARN 上运行的开源和商业项目，如 Apache Hive、Pig 等。

提供这些共同特征的努力需要创建一个框架来表达和优化这些工作负载的模型。
然后这个模型可以通过一个共享的底层库在 YARN 应用框架上应用和执行。
以下是对这样一个共享库的合理要求，我们之前已经通过与 MapReduce 的比较强调了这一点，一个充当共享底层的通用引擎。

_表达能力_。MapReduce 有一个简单的建模 API 来描述计算，
它通过要求所有的应用算法转化为 map 和 reduce 函数来描述计算的情况。
正如其他学者所观察到的，这太有约束性了，而面向 DAG 的模型可以更自然地捕获更广泛的组合。因此，我们将 Tez 的中心模型也定义为围绕 DAG 的执行。
此外，MapReduce 还为运行在 map/reduce 步骤中的逻辑提供了内置的语义，并强加了一个数据在 map 和 reduce 步骤之间的 _sorted_ 和 _partitioned_ 移动。
这些内置的语义，在一些核心用例中是合理的，在许多其他情况下可能是纯粹的开销，甚至在某些情况下是不需要的。
需要注意的是，这里需要一个 API 来描述任意 DAG 的结构，而不会添加一些不相关的语义到 DAG 结构中。

_数据平面的可定制性_。一旦分布式计算的结构被定义，就可以有在该结构中执行的实际逻辑的各种实现。这些不同之处可能是算法上的，例如，不同的数据分区方式，或与使用不同的硬件有关，例如，如果可以的话使用远程内存访问（RDMA）。
如果在 MapReduce 中，引擎的内置语义使得这样的定制化很难，因为它们侵入了引擎本身的实现。其次，在集群上执行 MapReduce 作业的单体结构使得插入独立的的实现很困难。
这就促使由数据转换和数据移动定义出的数据平面需要完全可定制。
还需要可以对任务执行的不同方面进行建模，以允许个别的执行的不同方面，例如读取输入、处理数据等等，可以很容易地进行定制。
我们采访了 Hadoop 社区的几位成员，证实了对现有引擎的改进(例如，改变 MapReduce 中的 shuffle 行为）是很有必要的。

虽然其他框架已经支持了 DAG 中的更一般概念，但是它们也有与 MapReduce 一样的局限性，内置的语义和数据平面的实现。而 Tez 能提供更低层次的抽象，这使得这样的语义和特殊实现能基于基础的共享脚手架来实现。

_后绑定的 runtime 优化_。应用从性能上考虑它们的数据处理逻辑时需要做出后绑定的决定。算法应该能基于被读取到的数据动态地变化，比如 join 的策略和扫描的机制。如果应用更好地理解它地数据和环境，就能更好地调整分区数和工作分工。Hadoop 集群的使用和负载特征上可以非常动态。用户和 jobs 持续地进出集群，它们的资源利用率却各不相同。这使得一个应用很难基于当前的集群状态去确定它的运行特征。我们把 Tez 设计成可以在 runtime 时更新核心抽象以使后绑定和在线决策更容易实现。

这就是我们对建立 Tez 的历史背景和合理性的概述。我们现在转向 Tez 的高层次架构，并且提供对关键构建块的一些看法。


## 3. 架构

Apache Tez 被设计和开发成专注于解决上面讨论过的这些问题，简而言之，1）底层模型的表达，2）数据平面的可定制性，3）促进 runtime 优化。与其建立一个通用计算引擎，我们意识到需要 Tez 去提供一个统一的框架来创建专门的引擎，以便为他们的特定需求定制数据处理。Tez 解决了通用但却困难的问题，编排和在 Hadoop 上执行分布式数据处理应用，使得应用可以专注于提供特定的语义和优化。应用层和 Tez 库层的关注点有着清晰的分界。Apache Tez 提供了集群资源的协调，容错性，资源弹性，安全性，内置的性能优化以及一个可随时使用的共享组件库。应用程序提供自定义应用逻辑，自定义数据平面和专门的优化。

这就带来了三个主要的好处：1）摊销开发成本（Hive 和 Pig 在 6 个月内用 Tez 库完全重写了它们的引擎），2）改进的性能（我们将在第 6 节展示用 Tez 有最高到 10 倍的性能改进），3）让未来多个引擎的管道更高效，因为它们共享了一个底层库。

Tez 由一组定义数据处理的核心 API 和一个在集群上启动的编排框架。应用程序应该实现这些 API 为编排框架提供执行环境。把 Tez 当作一个用于创建表示数据流结构的脚手架的库是很有用的，应用程序把自己的逻辑（比如算子）和数据传输代码（比如从远程机器的磁盘上读入数据）注入其中。这个设计即是战术性的也是战略性的。长期来看，这使得应用程序保持对 Tez 的未知，短期来看，这让现有的应用程序如 Hive 或 Pig 在不大幅改变它们的核心操作管道下能用上 Tez。我们开始描述 DAG API 和 Runtime API。这些是应用程序主要面对的接口，用来描述应用的 DAG 结构和执行时的代码。接着我们解释由 VertexManagers 和 DataSourceInitializers 组成的基于事件的控制平面去支持运行时对 DAG 的优化。最后，在第 4 节我们描述在 Hadoop 集群上执行所有代码的基于 YARN 的编排框架。特别地，我们专注于这个实现的性能和生产准备方面。


### 3.1 DAG API

Tez 的 DAG API 暴露给 runtime engine builders，作为一种以简洁的模式表达它们计算结构的方式。我们关注的是一类可以自然地表现为 DAGs 的数据处理应用，数据从数据源向数据汇，在中间的节点做数据转换。Tez 关注于无环图，而且通过假定在顶点上的确定性计算，在边上的数据流向，我们能基于容错重算，类似于 Dryad，进一步的解释在第 4.3 节。作为 DAG 的模型计算并不新鲜，但迄今为止，大多数系统在支持更高级别引擎的背景下一般都会设计 DAG APIs。Tez 被设计成把数据流程图建模作为主要关注点的系统。用众所周知的顶点和边的概念，DAG API 能给出一个关于计算结构的清晰和简洁的描述。

_顶点(Vertex)_。在 DAG API 中的一个顶点表示数据转换，是数据处理中的一步。这是作用到数据上的核心应用逻辑所在。因此一个顶点必须配置用户提供的 processor 类，并在其中定义每个 task 都要执行的逻辑。DAG 图中的一个“顶点”经常并行执行一些（可能是大量的）tasks。顶点的定义中控制了这个并行度。并行度通常由待处理的分布在集群上的数据决定或者是由需要切分成更小单元的大运算决定。一个顶点上 task 的并行度可以在 DAG 定义过程中静态地定义，但通常是在运行时动态地决定。

_边（Edge）_。DAG 图中的一条边表示从生产者顶点到消费者顶点的数据移动的逻辑和物理观点。
* _连接模式（Connection Pattern）_：从逻辑概念上看，一条边就是在生产者和消费者任务顶点的连接模式和它们的调度依赖关系。这使得编排框架能正确地把数据从生产者任务的输出传递到消费者任务的输入。这个路由表通过一个可拔插的 EdgeManagerPlugin API 接口配置实现。图 3 展示了 3 种常见的连接模式（one-to-one, broadcast, scatter-gather），能用来表达大多数的 DAG 连接，也是这个项目内置。对一些场景需要自定义路由，应用也可以通过自己实现自己的路由（在 5.2 节我们会给一个具体的例子）。
* _传输机制（Transport Mechanism）_：从物理概念上看，一条边就是实现移动数据的存储和传输机制。这可能是本地磁盘，或者本地/远程内存等等。一条边表示的实际的数据传输操作通过一对这条边指定互相兼容的 input 和 output 类执行的。兼容性基于使用相同的数据格式和物理传输机制。比如，两个操作都基于键值对格式和在磁盘上的操作，或者都基于字节流并使用内存。Tez 内置常用的 input 和 output 使用场景会在 4.1 节介绍。

Tez 用顶点的并行度和边的性质在执行过程中把逻辑 DAG 扩展成真实物理 task 执行的 DAG，如下图 2 所示。

![Figure 2: Expansion of the logical vertex DAG to a physical task DAG based on vertex parallelism and edge definition](/assets/img/post/tez-figure2.png "Expansion of the logical vertex DAG to a physical task DAG based on vertex parallelism and edge definition")

![Figure 3: Edge properties: define movement of data between producers and consumers](/assets/img/post/tez-figure3.png "Edge properties: define movement of data between producers and consumers")

_数据源和汇_。DAG 能通过 DAG API 来定义顶点和连接它们的边来定义。一般地，数据流会从一些数据源读取初始输入，并写入最终结果到一些数据汇中。数据源可以与一个 DataSourceInitializer 相关联，它在执行时能决定从初始输入的优化读取模式。比如，在 MapReduce 的术语中，这对应着 split 计算，一个 split 对应着被一个 map 任务读取的分布式数据的一个分片。对 map 任务的初始 split 计算能通过一个初始器完成，需要考虑数据的分布，数据的本地化，可获取的计算容量来决定 split 的数量以及对每个 split 的最优大小。类似的，数据汇可以和一个 DataSinkCommitter 相结合，它可以在运行时提交最终的输出。提交的定义随着输出类型的不同而不同，但是会保证只完成一次，而且通常会让外部观察者在成功输出结束后可以感知到。

这种 DAG 的组装方式允许可拔插和可重复使用的组件。输入输出的通用共享库能被不同的应用重复使用，因此只需要提供顶点的处理逻辑。反之，相同的 DAG 结构在不同的硬件环境中通过替换边上的不同的输入输出能以更优化的方式执行。Tez 自带一个适用于 Hadoop 平台内置的数据服务的输入输出库，即适用于 HDFS 和 YARN Shuffle Service。这使得 Hadoop 生态体系中的应用（比如 Hive 和 Pig）通过实现自定义处理器能很快地利用 Tez。图 4 展示了用 API 来描述逻辑 DAG 的一个浓缩例子。

![Figure 4: Essence of the Tez API shown via pseudo-code for the canonical WordCount example](/assets/img/post/tez-figure4.png "Essence of the Tez API shown via pseudo-code for the canonical WordCount example")


### 3.2 Runtime API

DAP API 定义了数据处理的脚手架结构。Runtime API 被用来将实际应用的代码注入脚手架中。具体来说，Runtime API 定义要实现的接口去创建上述 DAG 中指定的 processor，input 和 output 类。

_Inputs, Processor, Oouputs_。一个顶点是 DAG 图中一个转换步骤的逻辑表示。实际的转换是通过在集群的机器上运行该顶点的任务来完成的。Tez 定义每个 task 由一组 inputs，一个 processor，以及一组 outputs（IPO）组成。处理器是由该任务的顶点定义的。输入的定义是由该顶点的输入边上游的输出类定义的。输出由该顶点传出的边的输入类定义的。这使得处理器对处理过程有一个逻辑性观点，因此保留了在 MapReduce 中流行的简化编程模型。输入和输出隐藏了细节信息，比如数据传输，数据分区和/或分布式分片数据的汇聚。Runtime API 是一个瘦包装器（thin wrapper），用于实例化以及与输入，处理器和输出进行交互。在 IPO 对象创建后，它们就等着被配置了。

_IPO 配置_。框架通过在创建 DAG 时指定一个不透明的二进制有效载荷来配置 IPOs。这种二进制有效载荷的配置方式是一个常见的主题，用于配置 Tez 中任何应用特定实体。这允许应用使用它们选择的任何机制去实例化它们的代码。这样做不仅能做简单的配置，也能做代码注入（如 5.4 节的例子）。配置后，处理器被装备上所有输入和输出，并被要求执行。此后，由处理器，输入和输出来互相操作来完成任务。框架通过一个 context 对象和它们交互，发送和接收有关完成，更新进度，报告错误等事件。

_数据平面不可知_。Tez 没有指定任何数据格式，而且事实上在 DAG 执行时也不是数据平面的一部分。实际的数据传输由输入和输出完成，Tez 只是路由生产者和消费者之间的连接信息。当一个生产者任务输出产生数据，它接着发送相关元数据，比如数据的读取 URL 和大小，通过 Tez 给到消费者任务的输入。Tez 使用连接生产者和消费者的边所编码的连接模式来路由这些元数据。因此 Tez 在数据平面上增加的开销最小。这也使得 Tez 数据格式不可知。输入，处理器和输出能选择适用于应用的它们自己数据格式（比如 bytes，records 或者 key-value pairs 等等），在 5.5 节中所举例子。

这种新颖的基于 IPO 的任务组合方式允许关注点的分离，并使系统具备可拔插性。相同的 DAG 结构能基于环境相关的 IOs 进行实例化。比如，不同云环境能插入对它们存储子系统优化后的 IOs。我们在下节将会看到，如何在执行过程中动态地配置 IPOs，以及进一步地运行时定制。

### 3.3 基于事件的控制面板

Tez 编排框架地开放架构需要解耦控制平面以使各类实体互相交换控制信息。为了达到这样的效果 Tez 有一个基于事件的控制平面，同时也暴露给应用。软件组件生成事件路由给接收者。根据设计，这是一个异步，非阻塞，基于推送的通信方法。事件用作所有的通信，无论是框架发给框架，应用程序到框架，反之亦然。如图 5 中展示的，一个 DataEvent 由一个生产者任务的输出产生，包含输出元数据（比如 URL），以便给消费者任务去读取数据。这事件由框架接收，通过边指定的连接信息路由给消费者任务的输入。如果一个任务的输入在读取数据时发生错误，它会发送一个 ErrorEvent 给框架。基于这个错误事件，Tez 能重新执行生产者任务以重新生成数据。其他事件能用作发送统计数据，进度等等。基于事件的通信也提供了灵活性，可以在不改变交互模型或 APIs 的情况下增加更多的实体和通信渠道。Tez 只对事件进行路由。每个事件都有一个不透明的二进制有效载荷由发送方和接收方解释，以交换控制元数据。事件在每次任务心跳时流向和流出协调器。事件传输延迟取决于心跳延迟和协调器的处理延迟。这些延迟随着 job 的大小成比例地增加，因为它们依赖并发连接的数量和协调器能支持地事件负载。如果控制平面事件位于数据平面关键路径，那么它们会对应用延迟产生负面影响，但是如果它们只用作数据平面的设置，那么 Tez 就不会对低延迟的应用在数据平面上引入任何额外的延迟。

![Figure 5: Events used to route metadata between application IOs and error notifications from applications to the framework](/assets/img/post/tez-figure5.png "Figure 5: Events used to route metadata between application IOs and error notifications from applications to the framework")


### 3.4 顶点管理器：动态适应执行

如前所述，数据处理集群在计算能力和数据分布（数据存储在物理节点上的位置）方面存在差异，应用程序可以考虑这些差异来计划它们的工作。数据依赖性的行动，比如基于样本的范围分区或者分区裁剪的优化，都需要有在执行时改变 DAG 的能力。不可能对所有这些当前和未来的图的重新配置进行静态编码，Tez 也不能独自完成（因为它需要太多的领域知识）。因此 Tez 需要允许应用在执行时做出这样的决定并与 Tez 协调以动态调整 DAG 和它的执行。这都是通过 VertexManager 抽象完成的，类似于 [24] 。

_Runtime Graph Re-configuration_。

### 3.5 数据源初始器

## 4. 实现和使用性考虑

### 4.1 YARN 中的实现

### 4.2 执行效率

### 4.3 生产环境准备情况

## 5. 各种框架和接受度

### 5.1 Apache MapReduce

### 5.2 Apache Hive

### 5.3 Apache Pig

### 5.4 Apache Spark

### 5.5 Apache Flink

### 5.6 商业上的接受

### 5.7 部署

## 6. 实验结果

### 6.1 Hive 0.14 性能测试

### 6.2 Yahoo Hive 规模测试

### 6.3 Yahoo Pig 生产测试

### 6.4 Pig K-均值迭代测试

### 6.5 YARN 上的 Spark 多租户测试


## 7. 开源和未来的工作

## 8. 相关工作

## 9. 结论
